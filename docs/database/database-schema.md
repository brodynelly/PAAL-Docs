# Database Schema

## Overview

The PAAL system uses MongoDB as its primary database. MongoDB is a document-oriented NoSQL database that stores data in flexible, JSON-like documents. This document provides a comprehensive description of the database schema, including detailed collection structures, field specifications, relationships, indexing strategies, validation rules, and data management practices.

### Why MongoDB?

MongoDB was chosen for the PAAL system for several key reasons:

1. **Flexible Schema**: Allows for easy evolution of data models as requirements change
2. **Document Structure**: Natural fit for hierarchical data like farm → barn → stall relationships
3. **Horizontal Scalability**: Supports sharding for future growth
4. **Rich Query Language**: Powerful query capabilities including aggregation pipeline
5. **Change Streams**: Native support for real-time data updates
6. **Geospatial Support**: Built-in capabilities for location-based queries (for future farm mapping features)

### Database Design Principles

The database schema follows these design principles:

1. **Denormalization Where Appropriate**: Strategic denormalization to optimize read performance
2. **Normalization for Consistency**: Normalized references for data that changes frequently
3. **Indexing for Query Patterns**: Indexes designed based on actual query patterns
4. **Data Integrity**: Schema validation rules to ensure data consistency
5. **Performance Optimization**: Collection and index design optimized for common operations
6. **Future Scalability**: Design decisions made with future growth in mind

## Collections Overview

The database consists of the following main collections:

1. **Pigs**: Stores information about individual pigs
2. **Farms**: Stores information about farms
3. **Barns**: Stores information about barns within farms
4. **Stalls**: Stores information about stalls within barns
5. **Users**: Stores user account information
6. **PostureData**: Stores pig posture measurements
7. **PigHealthStatus**: Stores pig health status records
8. **PigBCS**: Stores body condition score records
9. **Devices**: Stores information about monitoring devices
10. **TemperatureData**: Stores temperature measurements
11. **ActivityLog**: Stores system activity logs

## Collection Schemas

### Pigs Collection

Stores information about individual pigs in the system. This is a core collection that maintains the primary data about each pig being monitored.

#### Schema Definition

```javascript
{
  _id: ObjectId,                // MongoDB generated ID
  pigId: Number,                // Unique pig identifier (integer)
  tag: String,                  // Pig tag/name (e.g., "PIG-001")
  breed: String,                // Pig breed (e.g., "Yorkshire")
  age: Number,                  // Age in months
  birthDate: Date,              // Date of birth (if known)
  weight: Number,               // Weight in kilograms
  gender: String,               // Gender ("male", "female")
  currentLocation: {            // Current location of the pig
    farmId: ObjectId,           // Reference to Farm collection
    barnId: ObjectId,           // Reference to Barn collection
    stallId: ObjectId           // Reference to Stall collection
  },
  healthRisk: Number,           // Calculated health risk score (0-1)
  active: Boolean,              // Whether the pig is active in the system
  status: String,               // Current status ("active", "sold", "deceased")
  notes: String,                // Additional notes about the pig
  metadata: {                   // Additional metadata
    source: String,             // Source of the pig (e.g., "born", "purchased")
    purchaseDate: Date,         // Date when the pig was purchased (if applicable)
    purchasePrice: Number,      // Purchase price (if applicable)
    genetics: {                 // Genetic information
      sire: String,             // Father's tag/ID
      dam: String               // Mother's tag/ID
    }
  },
  createdAt: Date,              // When the record was created
  updatedAt: Date               // When the record was last updated
}
```

#### Field Details

| Field | Type | Required | Description | Validation Rules |
|-------|------|----------|-------------|------------------|
| `_id` | ObjectId | Yes (auto) | MongoDB's auto-generated unique identifier | Generated by MongoDB |
| `pigId` | Number | Yes | Unique numeric identifier for the pig | Integer, unique, > 0 |
| `tag` | String | Yes | Human-readable tag/name for the pig | Non-empty string, unique, max 50 chars |
| `breed` | String | No | Breed of the pig | String, max 100 chars |
| `age` | Number | No | Age in months | Number ≥ 0 |
| `birthDate` | Date | No | Date of birth if known | Valid date, not in future |
| `weight` | Number | No | Weight in kilograms | Number > 0 |
| `gender` | String | No | Gender of the pig | Enum: "male", "female" |
| `currentLocation.farmId` | ObjectId | Yes | Reference to the farm | Valid ObjectId in Farms collection |
| `currentLocation.barnId` | ObjectId | No | Reference to the barn | Valid ObjectId in Barns collection |
| `currentLocation.stallId` | ObjectId | No | Reference to the stall | Valid ObjectId in Stalls collection |
| `healthRisk` | Number | No | Calculated health risk score | Number between 0 and 1 |
| `active` | Boolean | Yes | Whether the pig is active | Boolean |
| `status` | String | No | Current status | Enum: "active", "sold", "deceased" |
| `notes` | String | No | Additional notes | String, max 1000 chars |
| `metadata.source` | String | No | Source of the pig | String, max 100 chars |
| `metadata.purchaseDate` | Date | No | Purchase date | Valid date |
| `metadata.purchasePrice` | Number | No | Purchase price | Number ≥ 0 |
| `metadata.genetics.sire` | String | No | Father's tag/ID | String, max 50 chars |
| `metadata.genetics.dam` | String | No | Mother's tag/ID | String, max 50 chars |
| `createdAt` | Date | Yes (auto) | Creation timestamp | Auto-generated |
| `updatedAt` | Date | Yes (auto) | Last update timestamp | Auto-generated |

#### Sample Document

```javascript
{
  "_id": ObjectId("60d21b4667d0d8992e610c85"),
  "pigId": 1001,
  "tag": "PIG-1001",
  "breed": "Yorkshire",
  "age": 12,
  "birthDate": ISODate("2022-06-15T00:00:00.000Z"),
  "weight": 120.5,
  "gender": "female",
  "currentLocation": {
    "farmId": ObjectId("60d21b4667d0d8992e610c87"),
    "barnId": ObjectId("60d21b4667d0d8992e610c89"),
    "stallId": ObjectId("60d21b4667d0d8992e610c93")
  },
  "healthRisk": 0.2,
  "active": true,
  "status": "active",
  "notes": "Excellent health, good breeding candidate",
  "metadata": {
    "source": "purchased",
    "purchaseDate": ISODate("2022-06-15T00:00:00.000Z"),
    "purchasePrice": 500,
    "genetics": {
      "sire": "BOAR-42",
      "dam": "SOW-123"
    }
  },
  "createdAt": ISODate("2022-06-15T10:30:00.000Z"),
  "updatedAt": ISODate("2023-01-20T14:15:00.000Z")
}
```

#### Indexes

| Index | Fields | Type | Description | Justification |
|-------|--------|------|-------------|---------------|
| `pigId_1` | `{ pigId: 1 }` | Unique | Efficient lookups by pig ID | Primary lookup field, must be unique |
| `tag_1` | `{ tag: 1 }` | Unique | Efficient lookups by tag | Common lookup field, must be unique |
| `currentLocation.farmId_1` | `{ "currentLocation.farmId": 1 }` | Regular | Query pigs by farm | Common filter for listing pigs by farm |
| `currentLocation.barnId_1` | `{ "currentLocation.barnId": 1 }` | Regular | Query pigs by barn | Common filter for listing pigs by barn |
| `currentLocation.stallId_1` | `{ "currentLocation.stallId": 1 }` | Regular | Query pigs by stall | Common filter for listing pigs by stall |
| `active_1` | `{ active: 1 }` | Regular | Filter active/inactive pigs | Common filter condition |
| `status_1` | `{ status: 1 }` | Regular | Filter by status | Common filter condition |
| `breed_1` | `{ breed: 1 }` | Regular | Filter by breed | Used for breed-specific queries |
| `healthRisk_-1_updatedAt_-1` | `{ healthRisk: -1, updatedAt: -1 }` | Compound | Sort by health risk and update time | Used for health monitoring dashboards |
| `currentLocation.farmId_1_active_1` | `{ "currentLocation.farmId": 1, active: 1 }` | Compound | Filter by farm and active status | Common combined filter |

#### Common Queries

```javascript
// Find a specific pig by ID
db.pigs.findOne({ pigId: 1001 })

// Find all active pigs in a specific farm
db.pigs.find({
  "currentLocation.farmId": ObjectId("60d21b4667d0d8992e610c87"),
  "active": true
})

// Find pigs with high health risk
db.pigs.find({
  "healthRisk": { $gt: 0.7 },
  "active": true
}).sort({ healthRisk: -1 })

// Count pigs by breed
db.pigs.aggregate([
  { $match: { active: true } },
  { $group: { _id: "$breed", count: { $sum: 1 } } },
  { $sort: { count: -1 } }
])

// Find pigs in a specific stall
db.pigs.find({
  "currentLocation.stallId": ObjectId("60d21b4667d0d8992e610c93"),
  "active": true
})
```

#### Schema Validation

```javascript
db.createCollection("pigs", {
  validator: {
    $jsonSchema: {
      bsonType: "object",
      required: ["pigId", "tag", "currentLocation", "active"],
      properties: {
        pigId: {
          bsonType: "int",
          minimum: 1,
          description: "must be a positive integer and is required"
        },
        tag: {
          bsonType: "string",
          minLength: 1,
          maxLength: 50,
          description: "must be a non-empty string up to 50 characters and is required"
        },
        breed: {
          bsonType: "string",
          maxLength: 100,
          description: "must be a string up to 100 characters if the field exists"
        },
        age: {
          bsonType: "number",
          minimum: 0,
          description: "must be a non-negative number if the field exists"
        },
        birthDate: {
          bsonType: "date",
          description: "must be a valid date if the field exists"
        },
        weight: {
          bsonType: "number",
          minimum: 0,
          description: "must be a positive number if the field exists"
        },
        gender: {
          enum: ["male", "female"],
          description: "must be either 'male' or 'female' if the field exists"
        },
        currentLocation: {
          bsonType: "object",
          required: ["farmId"],
          properties: {
            farmId: {
              bsonType: "objectId",
              description: "must be an objectId and is required"
            },
            barnId: {
              bsonType: "objectId",
              description: "must be an objectId if the field exists"
            },
            stallId: {
              bsonType: "objectId",
              description: "must be an objectId if the field exists"
            }
          }
        },
        healthRisk: {
          bsonType: "number",
          minimum: 0,
          maximum: 1,
          description: "must be a number between 0 and 1 if the field exists"
        },
        active: {
          bsonType: "bool",
          description: "must be a boolean and is required"
        },
        status: {
          enum: ["active", "sold", "deceased"],
          description: "must be one of 'active', 'sold', or 'deceased' if the field exists"
        }
        // Additional validation rules for other fields...
      }
    }
  },
  validationLevel: "strict",
  validationAction: "error"
});
```

### Farms Collection

Stores information about farms in the system.

```javascript
{
  _id: ObjectId,                // MongoDB generated ID
  name: String,                 // Farm name
  location: String,             // Farm location/address
  description: String,          // Farm description
  isActive: Boolean,            // Whether the farm is active
  createdAt: Date,              // When the record was created
  updatedAt: Date               // When the record was last updated
}
```

**Indexes:**
- `name`: Index for searching farms by name
- `isActive`: Index for filtering active/inactive farms

### Barns Collection

Stores information about barns within farms.

```javascript
{
  _id: ObjectId,                // MongoDB generated ID
  name: String,                 // Barn name
  farmId: ObjectId,             // Reference to Farm collection
  description: String,          // Barn description
  createdAt: Date,              // When the record was created
  updatedAt: Date               // When the record was last updated
}
```

**Indexes:**
- `farmId`: Index for querying barns by farm
- `name`: Index for searching barns by name

### Stalls Collection

Stores information about stalls within barns.

```javascript
{
  _id: ObjectId,                // MongoDB generated ID
  name: String,                 // Stall name
  farmId: ObjectId,             // Reference to Farm collection
  barnId: ObjectId,             // Reference to Barn collection
  capacity: Number,             // Stall capacity (number of pigs)
  description: String,          // Stall description
  createdAt: Date,              // When the record was created
  updatedAt: Date               // When the record was last updated
}
```

**Indexes:**
- `farmId`: Index for querying stalls by farm
- `barnId`: Index for querying stalls by barn
- `name`: Index for searching stalls by name

### Users Collection

Stores user account information.

```javascript
{
  _id: ObjectId,                // MongoDB generated ID
  email: String,                // User email (unique)
  password: String,             // Hashed password
  firstName: String,            // User's first name
  lastName: String,             // User's last name
  role: String,                 // User role (admin, manager, farmer, viewer)
  isActive: Boolean,            // Whether the user account is active
  lastLogin: Date,              // When the user last logged in
  assignedFarm: ObjectId,       // Reference to Farm collection (for farmers)
  permissions: [String],        // Array of permission strings
  createdAt: Date,              // When the record was created
  updatedAt: Date               // When the record was last updated
}
```

**Indexes:**
- `email`: Unique index for user lookup by email
- `role`: Index for filtering users by role
- `assignedFarm`: Index for querying users by assigned farm
- `isActive`: Index for filtering active/inactive users

### PostureData Collection

Stores pig posture measurements.

```javascript
{
  _id: ObjectId,                // MongoDB generated ID
  pigId: Number,                // Reference to Pig collection (pigId field)
  timestamp: Date,              // When the measurement was taken
  score: Number,                // Posture score (0-5)
                                // 0: Standing
                                // 1: Sitting
                                // 2: Lying on side
                                // 3: Lying on belly
                                // 4: Moving
                                // 5: Other
}
```

**Indexes:**
- `pigId`: Index for querying posture data by pig
- `timestamp`: Index for time-based queries
- `pigId_timestamp`: Compound index for efficient queries by pig and time

### PigHealthStatus Collection

Stores pig health status records.

```javascript
{
  _id: ObjectId,                // MongoDB generated ID
  pigId: Number,                // Reference to Pig collection (pigId field)
  timestamp: Date,              // When the status was recorded
  status: String,               // Health status (healthy, at risk, critical, no movement)
  notes: String,                // Additional notes about the health status
  recordedBy: ObjectId          // Reference to User collection (who recorded this)
}
```

**Indexes:**
- `pigId`: Index for querying health status by pig
- `timestamp`: Index for time-based queries
- `pigId_timestamp`: Compound index for efficient queries by pig and time
- `status`: Index for filtering by status

### PigBCS Collection

Stores body condition score records.

```javascript
{
  _id: ObjectId,                // MongoDB generated ID
  pigId: Number,                // Reference to Pig collection (pigId field)
  timestamp: Date,              // When the score was recorded
  score: Number,                // Body condition score (1-5)
  notes: String,                // Additional notes about the score
  recordedBy: ObjectId          // Reference to User collection (who recorded this)
}
```

**Indexes:**
- `pigId`: Index for querying BCS by pig
- `timestamp`: Index for time-based queries
- `pigId_timestamp`: Compound index for efficient queries by pig and time

### Devices Collection

Stores information about monitoring devices.

```javascript
{
  _id: ObjectId,                // MongoDB generated ID
  deviceId: String,             // Unique device identifier
  type: String,                 // Device type (temperature, posture, etc.)
  location: {                   // Device location
    farmId: ObjectId,           // Reference to Farm collection
    barnId: ObjectId,           // Reference to Barn collection
    stallId: ObjectId           // Reference to Stall collection
  },
  status: String,               // Device status (active, inactive, maintenance)
  lastSeen: Date,               // When the device last communicated
  firmware: String,             // Device firmware version
  createdAt: Date,              // When the record was created
  updatedAt: Date               // When the record was last updated
}
```

**Indexes:**
- `deviceId`: Unique index for device lookup
- `location.farmId`: Index for querying devices by farm
- `location.barnId`: Index for querying devices by barn
- `location.stallId`: Index for querying devices by stall
- `status`: Index for filtering by status
- `type`: Index for filtering by device type

### TemperatureData Collection

Stores temperature measurements.

```javascript
{
  _id: ObjectId,                // MongoDB generated ID
  deviceId: String,             // Reference to Device collection (deviceId field)
  timestamp: Date,              // When the measurement was taken
  temperature: Number,          // Temperature in Celsius
  humidity: Number,             // Humidity percentage (optional)
  location: {                   // Measurement location
    farmId: ObjectId,           // Reference to Farm collection
    barnId: ObjectId,           // Reference to Barn collection
    stallId: ObjectId           // Reference to Stall collection
  }
}
```

**Indexes:**
- `deviceId`: Index for querying temperature data by device
- `timestamp`: Index for time-based queries
- `deviceId_timestamp`: Compound index for efficient queries by device and time
- `location.farmId`: Index for querying temperature data by farm
- `location.barnId`: Index for querying temperature data by barn
- `location.stallId`: Index for querying temperature data by stall

### ActivityLog Collection

Stores system activity logs.

```javascript
{
  _id: ObjectId,                // MongoDB generated ID
  type: String,                 // Activity type (user, pig, farm, etc.)
  action: String,               // Action performed (created, updated, deleted, login, etc.)
  description: String,          // Human-readable description of the activity
  timestamp: Date,              // When the activity occurred
  userId: ObjectId,             // Reference to User collection (who performed the action)
  entityId: ObjectId,           // Reference to the affected entity (if applicable)
  ipAddress: String,            // IP address of the user (for user actions)
  metadata: Object              // Additional metadata about the activity
}
```

**Indexes:**
- `timestamp`: Index for time-based queries
- `type`: Index for filtering by activity type
- `action`: Index for filtering by action
- `userId`: Index for querying activities by user
- `entityId`: Index for querying activities by affected entity

## Relationships

The database schema includes several relationships between collections:

### One-to-Many Relationships

- **Farm to Barns**: One farm can have many barns
  - Implemented via the `farmId` field in the Barns collection

- **Barn to Stalls**: One barn can have many stalls
  - Implemented via the `barnId` field in the Stalls collection

- **Farm to Users**: One farm can have many assigned users
  - Implemented via the `assignedFarm` field in the Users collection

- **Pig to PostureData**: One pig can have many posture measurements
  - Implemented via the `pigId` field in the PostureData collection

- **Pig to PigHealthStatus**: One pig can have many health status records
  - Implemented via the `pigId` field in the PigHealthStatus collection

- **Pig to PigBCS**: One pig can have many body condition score records
  - Implemented via the `pigId` field in the PigBCS collection

- **User to ActivityLog**: One user can have many activity logs
  - Implemented via the `userId` field in the ActivityLog collection

### Many-to-One Relationships

- **Pig to Farm/Barn/Stall**: Many pigs can be in one farm/barn/stall
  - Implemented via the `currentLocation` object in the Pigs collection

- **Device to Farm/Barn/Stall**: Many devices can be in one farm/barn/stall
  - Implemented via the `location` object in the Devices collection

- **TemperatureData to Device**: Many temperature measurements can come from one device
  - Implemented via the `deviceId` field in the TemperatureData collection

## Indexing Strategy

The database employs a comprehensive indexing strategy to optimize query performance while balancing write performance and storage requirements. This section details the types of indexes used, their purposes, and the considerations that went into their design.

### Index Types and Usage

#### Single Field Indexes

Single field indexes are used for simple equality queries, range queries, sorting, and existence checks.

| Collection | Index | Purpose | Example Query |
|------------|-------|---------|--------------|
| `Pigs` | `{ pigId: 1 }` | Lookup by pig ID | `db.pigs.findOne({ pigId: 1001 })` |
| `Farms` | `{ name: 1 }` | Search farms by name | `db.farms.find({ name: "Farm 1" })` |
| `Users` | `{ email: 1 }` | Lookup user by email | `db.users.findOne({ email: "user@example.com" })` |
| `PostureData` | `{ timestamp: -1 }` | Sort by timestamp descending | `db.postureData.find().sort({ timestamp: -1 })` |
| `Devices` | `{ status: 1 }` | Filter devices by status | `db.devices.find({ status: "active" })` |

#### Compound Indexes

Compound indexes support queries that filter or sort on multiple fields, optimizing complex query patterns.

| Collection | Index | Purpose | Example Query |
|------------|-------|---------|--------------|
| `PostureData` | `{ pigId: 1, timestamp: -1 }` | Find posture data for a pig, sorted by time | `db.postureData.find({ pigId: 1001 }).sort({ timestamp: -1 })` |
| `Pigs` | `{ "currentLocation.farmId": 1, active: 1 }` | Find active pigs in a farm | `db.pigs.find({ "currentLocation.farmId": farmId, active: true })` |
| `ActivityLog` | `{ type: 1, timestamp: -1 }` | Find activities by type, sorted by time | `db.activityLog.find({ type: "pig" }).sort({ timestamp: -1 })` |
| `TemperatureData` | `{ deviceId: 1, timestamp: -1 }` | Find temperature data for a device, sorted by time | `db.temperatureData.find({ deviceId: "DEV-001" }).sort({ timestamp: -1 })` |
| `PigHealthStatus` | `{ pigId: 1, status: 1, timestamp: -1 }` | Find health records by pig and status | `db.pigHealthStatus.find({ pigId: 1001, status: "at risk" }).sort({ timestamp: -1 })` |

#### Text Indexes

Text indexes enable full-text search capabilities across text fields.

| Collection | Index | Purpose | Example Query |
|------------|-------|---------|--------------|
| `Farms` | `{ name: "text", description: "text" }` | Search farms by name or description | `db.farms.find({ $text: { $search: "organic dairy" } })` |
| `Pigs` | `{ notes: "text" }` | Search pig notes for keywords | `db.pigs.find({ $text: { $search: "breeding candidate" } })` |
| `ActivityLog` | `{ description: "text" }` | Search activity descriptions | `db.activityLog.find({ $text: { $search: "health check" } })` |

#### Geospatial Indexes

Geospatial indexes support location-based queries (for future farm mapping features).

| Collection | Index | Purpose | Example Query |
|------------|-------|---------|--------------|
| `Farms` | `{ geoLocation: "2dsphere" }` | Find farms near a location | `db.farms.find({ geoLocation: { $near: { $geometry: { type: "Point", coordinates: [ -73.9667, 40.78 ] }, $maxDistance: 5000 } } })` |

#### Partial Indexes

Partial indexes only index a subset of documents, reducing index size and improving performance.

| Collection | Index | Purpose | Example Query |
|------------|-------|---------|--------------|
| `Pigs` | `{ healthRisk: -1 }` with filter `{ active: true }` | Index only active pigs by health risk | `db.pigs.find({ active: true }).sort({ healthRisk: -1 })` |
| `Devices` | `{ lastSeen: -1 }` with filter `{ status: "active" }` | Index only active devices by last seen time | `db.devices.find({ status: "active" }).sort({ lastSeen: -1 })` |

### Index Design Considerations

#### Query Pattern Analysis

Indexes are designed based on a thorough analysis of application query patterns:

1. **Frequency Analysis**: Indexes prioritize the most frequently executed queries
2. **Performance Profiling**: Slow queries are identified and optimized with appropriate indexes
3. **Query Shape Analysis**: Queries with similar shapes share indexes where possible

#### Performance Balancing

The indexing strategy balances several performance considerations:

1. **Read vs. Write Performance**:
   - Each index improves read performance but adds overhead to write operations
   - Collections with high write-to-read ratios have fewer indexes
   - Collections with high read-to-write ratios have more comprehensive indexing

2. **Index Size and Memory Usage**:
   - Total index size is monitored to ensure it fits within available RAM
   - Compound indexes are designed to support multiple query patterns where possible
   - Partial indexes are used to reduce index size for large collections

3. **Index Selectivity**:
   - More selective fields (with higher cardinality) are placed first in compound indexes
   - Low-selectivity fields (like boolean flags) are typically not indexed alone
   - Exception: When low-selectivity fields are frequently used in queries that return small result sets

#### Index Maintenance

The indexing strategy includes ongoing maintenance procedures:

1. **Index Usage Monitoring**:
   - Regular monitoring of index usage statistics
   - Unused indexes are identified and removed
   - Missing indexes are identified through query performance analysis

2. **Index Build Strategy**:
   - New indexes are built during low-traffic periods
   - Background index builds are used for production environments
   - Index builds are staggered to minimize impact on system performance

3. **Index Optimization**:
   - Periodic review and optimization of existing indexes
   - Consolidation of overlapping indexes
   - Reindexing when necessary to reduce fragmentation

### Index Implementation Example

Here's an example of how indexes are created for the Pigs collection:

```javascript
// Create single field indexes
db.pigs.createIndex({ pigId: 1 }, { unique: true });
db.pigs.createIndex({ tag: 1 }, { unique: true });
db.pigs.createIndex({ "currentLocation.farmId": 1 });
db.pigs.createIndex({ "currentLocation.barnId": 1 });
db.pigs.createIndex({ "currentLocation.stallId": 1 });
db.pigs.createIndex({ active: 1 });
db.pigs.createIndex({ breed: 1 });

// Create compound indexes
db.pigs.createIndex({ "currentLocation.farmId": 1, active: 1 });
db.pigs.createIndex({ healthRisk: -1, updatedAt: -1 });

// Create text index
db.pigs.createIndex({ notes: "text" });

// Create partial index
db.pigs.createIndex(
  { healthRisk: -1 },
  { partialFilterExpression: { active: true } }
);
```

### Index Performance Monitoring

The system includes tools for monitoring index performance:

1. **Query Profiling**:
   ```javascript
   // Enable profiling for slow queries
   db.setProfilingLevel(1, { slowms: 100 });

   // Analyze slow queries
   db.system.profile.find({ millis: { $gt: 100 } }).sort({ ts: -1 });
   ```

2. **Index Statistics**:
   ```javascript
   // Get index statistics for a collection
   db.pigs.stats().indexSizes;

   // Get detailed index usage statistics
   db.pigs.aggregate([
     { $indexStats: {} }
   ]);
   ```

3. **Explain Plans**:
   ```javascript
   // Analyze query execution plan
   db.pigs.find({ "currentLocation.farmId": farmId, active: true })
     .sort({ healthRisk: -1 })
     .explain("executionStats");
   ```

## Data Validation

MongoDB schema validation is used to ensure data integrity:

```javascript
db.createCollection("pigs", {
  validator: {
    $jsonSchema: {
      bsonType: "object",
      required: ["pigId", "tag", "currentLocation", "active"],
      properties: {
        pigId: {
          bsonType: "int",
          description: "must be an integer and is required"
        },
        tag: {
          bsonType: "string",
          description: "must be a string and is required"
        },
        breed: {
          bsonType: "string",
          description: "must be a string if the field exists"
        },
        age: {
          bsonType: "int",
          minimum: 0,
          description: "must be a non-negative integer if the field exists"
        },
        currentLocation: {
          bsonType: "object",
          required: ["farmId"],
          properties: {
            farmId: {
              bsonType: "objectId",
              description: "must be an objectId and is required"
            },
            barnId: {
              bsonType: "objectId",
              description: "must be an objectId if the field exists"
            },
            stallId: {
              bsonType: "objectId",
              description: "must be an objectId if the field exists"
            }
          }
        },
        active: {
          bsonType: "bool",
          description: "must be a boolean and is required"
        }
      }
    }
  }
});
```

## Data Migration and Versioning

As the application evolves, the database schema needs to change to accommodate new features, fix issues, or improve performance. This section details the comprehensive strategy for managing schema changes and data migrations.

### Schema Versioning

The system maintains a dedicated `schemaVersion` collection to track the current version of each collection's schema:

```javascript
// Example document in the schemaVersion collection
{
  "_id": "pigs",                // Collection name
  "version": 3,                 // Current schema version
  "description": "Added health risk calculation fields",  // Description of latest change
  "updatedAt": ISODate("2023-06-15T10:30:00.000Z"),      // When the schema was last updated
  "updatedBy": "migration-script-v3",                    // What updated the schema
  "history": [                  // History of schema changes
    {
      "version": 1,
      "description": "Initial schema",
      "updatedAt": ISODate("2022-01-10T09:00:00.000Z")
    },
    {
      "version": 2,
      "description": "Added metadata fields",
      "updatedAt": ISODate("2022-08-22T14:45:00.000Z")
    },
    {
      "version": 3,
      "description": "Added health risk calculation fields",
      "updatedAt": ISODate("2023-06-15T10:30:00.000Z")
    }
  ]
}
```

### Migration Types

The system supports several types of migrations:

#### 1. Additive Migrations

Adding new fields or indexes without modifying existing data:

```javascript
// Add a new field to all pigs with a default value
db.pigs.updateMany(
  {}, // Match all documents
  {
    $set: {
      "healthRisk": 0  // Default value
    }
  }
);

// Add a new index for the new field
db.pigs.createIndex({ healthRisk: -1 });
```

#### 2. Transformative Migrations

Modifying existing data to conform to new schema requirements:

```javascript
// Transform string age values to numbers
db.pigs.find({ age: { $type: "string" } }).forEach(function(pig) {
  db.pigs.updateOne(
    { _id: pig._id },
    { $set: { age: parseInt(pig.age) } }
  );
});
```

#### 3. Structural Migrations

Changing the structure of documents:

```javascript
// Restructure location data from flat fields to nested object
db.pigs.find({
  farmId: { $exists: true },
  barnId: { $exists: true },
  stallId: { $exists: true }
}).forEach(function(pig) {
  db.pigs.updateOne(
    { _id: pig._id },
    {
      $set: {
        "currentLocation": {
          farmId: pig.farmId,
          barnId: pig.barnId,
          stallId: pig.stallId
        }
      },
      $unset: {
        farmId: "",
        barnId: "",
        stallId: ""
      }
    }
  );
});
```

#### 4. Collection Migrations

Moving data between collections:

```javascript
// Move temperature data to a new collection
db.deviceData.find({ type: "temperature" }).forEach(function(data) {
  db.temperatureData.insertOne({
    deviceId: data.deviceId,
    timestamp: data.timestamp,
    temperature: data.value,
    location: data.location
  });
});
```

### Migration Framework

The system uses a custom migration framework to manage and execute migrations:

```javascript
// Migration script structure
const migration = {
  version: 3,
  collection: "pigs",
  description: "Add health risk calculation fields",
  up: async function(db) {
    // Add new fields
    await db.collection("pigs").updateMany(
      {},
      {
        $set: {
          "healthRisk": 0,
          "healthFactors": {
            "posture": 0,
            "temperature": 0,
            "feeding": 0
          }
        }
      }
    );

    // Create new indexes
    await db.collection("pigs").createIndex({ healthRisk: -1 });

    // Update schema version
    await db.collection("schemaVersion").updateOne(
      { _id: "pigs" },
      {
        $set: {
          version: this.version,
          description: this.description,
          updatedAt: new Date(),
          updatedBy: "migration-script-v3"
        },
        $push: {
          history: {
            version: this.version,
            description: this.description,
            updatedAt: new Date()
          }
        }
      },
      { upsert: true }
    );
  },
  down: async function(db) {
    // Remove fields
    await db.collection("pigs").updateMany(
      {},
      {
        $unset: {
          "healthRisk": "",
          "healthFactors": ""
        }
      }
    );

    // Remove indexes
    await db.collection("pigs").dropIndex({ healthRisk: -1 });

    // Update schema version
    await db.collection("schemaVersion").updateOne(
      { _id: "pigs" },
      {
        $set: {
          version: this.version - 1,
          updatedAt: new Date(),
          updatedBy: "migration-rollback-v3"
        }
      }
    );
  }
};
```

### Migration Execution Process

Migrations are executed through a controlled process:

1. **Development**:
   - Migrations are developed and tested in development environments
   - Each migration is stored as a separate JavaScript file with up/down methods
   - Migrations are version-controlled in the codebase

2. **Testing**:
   - Migrations are tested on copies of production data
   - Both up and down migrations are verified
   - Performance impact is assessed

3. **Deployment**:
   - Migrations are deployed during scheduled maintenance windows
   - A backup is taken before running migrations
   - Migrations are run in a transaction where possible
   - Application is put in maintenance mode during complex migrations

4. **Verification**:
   - Data integrity is verified after migration
   - Application functionality is tested with migrated data
   - Performance is monitored after migration

### Migration Command Line Tool

The system includes a command-line tool for managing migrations:

```bash
# List all migrations and their status
node scripts/migrate.js list

# Run pending migrations
node scripts/migrate.js up

# Run specific migration
node scripts/migrate.js up --version 3 --collection pigs

# Rollback last migration
node scripts/migrate.js down

# Rollback to specific version
node scripts/migrate.js down --version 2 --collection pigs
```

### Schema Evolution Examples

Here are examples of how the schema has evolved over time:

#### Pigs Collection Evolution

| Version | Changes | Migration Script |
|---------|---------|------------------|
| 1 | Initial schema with basic fields | N/A |
| 2 | Added metadata fields for tracking pig sources | `migrations/pigs_v2.js` |
| 3 | Added health risk calculation fields | `migrations/pigs_v3.js` |
| 4 | Restructured location data to support hierarchical queries | `migrations/pigs_v4.js` |

#### Example Migration Script

```javascript
// migrations/pigs_v3.js
module.exports = {
  version: 3,
  collection: "pigs",
  description: "Add health risk calculation fields",

  up: async function(db) {
    console.log(`Running migration: ${this.collection} v${this.version} - ${this.description}`);

    // Step 1: Add new fields with default values
    await db.collection("pigs").updateMany(
      {},
      {
        $set: {
          "healthRisk": 0,
          "healthFactors": {
            "posture": 0,
            "temperature": 0,
            "feeding": 0
          }
        }
      }
    );
    console.log("Added health risk fields to all pigs");

    // Step 2: Calculate initial health risk values based on existing data
    const pigs = await db.collection("pigs").find({}).toArray();

    for (const pig of pigs) {
      // Get latest posture data
      const postureData = await db.collection("postureData")
        .find({ pigId: pig.pigId })
        .sort({ timestamp: -1 })
        .limit(10)
        .toArray();

      // Calculate health factors based on posture data
      let postureRisk = 0;
      if (postureData.length > 0) {
        // Calculate lying percentage
        const lyingCount = postureData.filter(p => p.score === 2 || p.score === 3).length;
        const lyingPercentage = (lyingCount / postureData.length) * 100;

        // Higher risk if pig is lying down too much
        if (lyingPercentage > 70) {
          postureRisk = 0.3;
        } else if (lyingPercentage > 50) {
          postureRisk = 0.1;
        }
      }

      // Update pig with calculated risk
      await db.collection("pigs").updateOne(
        { _id: pig._id },
        {
          $set: {
            "healthFactors.posture": postureRisk,
            "healthRisk": postureRisk // Simple calculation for now
          }
        }
      );
    }
    console.log("Calculated initial health risk values");

    // Step 3: Create new indexes
    await db.collection("pigs").createIndex({ healthRisk: -1 });
    console.log("Created index on healthRisk field");

    // Step 4: Update schema version
    await db.collection("schemaVersion").updateOne(
      { _id: "pigs" },
      {
        $set: {
          version: this.version,
          description: this.description,
          updatedAt: new Date(),
          updatedBy: "migration-script-v3"
        },
        $push: {
          history: {
            version: this.version,
            description: this.description,
            updatedAt: new Date()
          }
        }
      },
      { upsert: true }
    );
    console.log("Updated schema version");
  },

  down: async function(db) {
    console.log(`Rolling back migration: ${this.collection} v${this.version}`);

    // Step 1: Remove indexes
    await db.collection("pigs").dropIndex({ healthRisk: -1 });
    console.log("Dropped index on healthRisk field");

    // Step 2: Remove fields
    await db.collection("pigs").updateMany(
      {},
      {
        $unset: {
          "healthRisk": "",
          "healthFactors": ""
        }
      }
    );
    console.log("Removed health risk fields from all pigs");

    // Step 3: Update schema version
    await db.collection("schemaVersion").updateOne(
      { _id: "pigs" },
      {
        $set: {
          version: this.version - 1,
          updatedAt: new Date(),
          updatedBy: "migration-rollback-v3"
        }
      }
    );
    console.log("Updated schema version");
  }
};
```

## Backup and Recovery

The PAAL system implements a comprehensive backup and recovery strategy to ensure data durability and availability. This section details the backup procedures, recovery processes, and disaster recovery planning.

### Backup Strategy

The backup strategy employs multiple approaches to ensure data safety:

#### 1. Full Backups

Full backups capture the entire database state:

```bash
# Daily full backup script
#!/bin/bash
DATE=$(date +%Y%m%d)
BACKUP_DIR="/backup/mongodb/full/$DATE"
LOG_FILE="/var/log/mongodb/backup_$DATE.log"

# Create backup directory
mkdir -p $BACKUP_DIR

# Perform backup with compression
mongodump \
  --host mongodb.example.com \
  --port 27017 \
  --username backup_user \
  --password "$BACKUP_PASSWORD" \
  --authenticationDatabase admin \
  --db paal \
  --out $BACKUP_DIR \
  --gzip \
  >> $LOG_FILE 2>&1

# Verify backup
echo "Verifying backup..." >> $LOG_FILE
mongorestore \
  --host mongodb-verify.example.com \
  --port 27017 \
  --username verify_user \
  --password "$VERIFY_PASSWORD" \
  --authenticationDatabase admin \
  --db paal_verify \
  --drop \
  --gzip \
  $BACKUP_DIR/paal \
  --dryRun \
  >> $LOG_FILE 2>&1

# Rotate backups (keep last 30 days)
find /backup/mongodb/full -type d -mtime +30 -exec rm -rf {} \;
```

**Schedule**: Daily at 1:00 AM UTC
**Retention**: 30 days

#### 2. Incremental Backups

Incremental backups capture changes since the last backup using the MongoDB oplog:

```bash
# Hourly incremental backup script
#!/bin/bash
DATE=$(date +%Y%m%d_%H)
BACKUP_DIR="/backup/mongodb/incremental/$DATE"
LOG_FILE="/var/log/mongodb/incremental_$DATE.log"
LAST_TIMESTAMP_FILE="/var/lib/mongodb-backup/last_oplog_timestamp"

# Create backup directory
mkdir -p $BACKUP_DIR

# Get last oplog timestamp
if [ -f $LAST_TIMESTAMP_FILE ]; then
  LAST_TIMESTAMP=$(cat $LAST_TIMESTAMP_FILE)
  QUERY="{\"ts\":{\"\\$gt\":{\"\\$timestamp\":{\"t\":$LAST_TIMESTAMP,\"i\":1}}}}"
else
  # If no timestamp file exists, get all oplog entries from the last hour
  ONE_HOUR_AGO=$(date -d "1 hour ago" +%s)
  QUERY="{\"ts\":{\"\\$gt\":{\"\\$timestamp\":{\"t\":$ONE_HOUR_AGO,\"i\":1}}}}"
fi

# Perform oplog backup
mongodump \
  --host mongodb.example.com \
  --port 27017 \
  --username backup_user \
  --password "$BACKUP_PASSWORD" \
  --authenticationDatabase admin \
  --db local \
  --collection oplog.rs \
  --query "$QUERY" \
  --out $BACKUP_DIR \
  --gzip \
  >> $LOG_FILE 2>&1

# Get and save the latest oplog timestamp
LATEST_TIMESTAMP=$(mongo \
  --host mongodb.example.com \
  --port 27017 \
  --username backup_user \
  --password "$BACKUP_PASSWORD" \
  --authenticationDatabase admin \
  --quiet \
  --eval "db.getSiblingDB('local').oplog.rs.find({}, {ts:1}).sort({ts:-1}).limit(1).next().ts.t")

echo $LATEST_TIMESTAMP > $LAST_TIMESTAMP_FILE

# Rotate incremental backups (keep last 48 hours)
find /backup/mongodb/incremental -type d -mtime +2 -exec rm -rf {} \;
```

**Schedule**: Hourly
**Retention**: 48 hours

#### 3. Replica Set Replication

The MongoDB deployment uses a replica set configuration for real-time data redundancy:

```javascript
// Replica set configuration
{
  "_id": "paal-rs",
  "members": [
    {
      "_id": 0,
      "host": "mongodb-primary.example.com:27017",
      "priority": 2
    },
    {
      "_id": 1,
      "host": "mongodb-secondary-1.example.com:27017",
      "priority": 1
    },
    {
      "_id": 2,
      "host": "mongodb-secondary-2.example.com:27017",
      "priority": 1
    },
    {
      "_id": 3,
      "host": "mongodb-arbiter.example.com:27017",
      "arbiterOnly": true
    }
  ],
  "settings": {
    "chainingAllowed": true,
    "heartbeatTimeoutSecs": 10,
    "electionTimeoutMillis": 10000,
    "catchUpTimeoutMillis": 60000
  }
}
```

#### 4. Cloud Backup Storage

Backups are stored in multiple locations:

1. **Local Storage**: For fast recovery from common failures
2. **Off-site Storage**: For disaster recovery
3. **Cloud Storage**: Encrypted backups in AWS S3 with lifecycle policies

```bash
# Script to upload backups to AWS S3
#!/bin/bash
DATE=$(date +%Y%m%d)
BACKUP_DIR="/backup/mongodb/full/$DATE"
S3_BUCKET="paal-mongodb-backups"
S3_PREFIX="full/$DATE"

# Encrypt backup files
tar -czf - $BACKUP_DIR | \
  openssl enc -aes-256-cbc -salt -pass file:/etc/mongodb-backup/encryption_key \
  > /tmp/mongodb_backup_$DATE.tar.gz.enc

# Upload to S3
aws s3 cp \
  /tmp/mongodb_backup_$DATE.tar.gz.enc \
  s3://$S3_BUCKET/$S3_PREFIX/mongodb_backup_$DATE.tar.gz.enc \
  --storage-class STANDARD_IA

# Clean up
rm /tmp/mongodb_backup_$DATE.tar.gz.enc

# Verify upload
aws s3api head-object \
  --bucket $S3_BUCKET \
  --key $S3_PREFIX/mongodb_backup_$DATE.tar.gz.enc
```

### Recovery Procedures

The system supports multiple recovery scenarios:

#### 1. Point-in-Time Recovery

Restore the database to a specific point in time:

```bash
#!/bin/bash
# Point-in-Time Recovery Script

# Parameters
TARGET_DATE="2023-06-15"
TARGET_TIME="14:30:00"
RESTORE_DB="paal"
TEMP_DB="paal_restore"

# Convert target date/time to timestamp
TARGET_TIMESTAMP=$(date -d "$TARGET_DATE $TARGET_TIME" +%s)

# Step 1: Find the most recent full backup before the target time
BACKUP_DIR=$(find /backup/mongodb/full -type d -name "2023*" | sort | grep -v "$TARGET_DATE" | tail -1)
if [ -z "$BACKUP_DIR" ]; then
  echo "No suitable full backup found before $TARGET_DATE"
  exit 1
fi

# Step 2: Restore the full backup to a temporary database
mongorestore \
  --host mongodb-restore.example.com \
  --port 27017 \
  --username restore_user \
  --password "$RESTORE_PASSWORD" \
  --authenticationDatabase admin \
  --db $TEMP_DB \
  --gzip \
  $BACKUP_DIR/$RESTORE_DB

# Step 3: Find all incremental backups between the full backup and target time
FULL_BACKUP_DATE=$(basename $BACKUP_DIR)
INCREMENTAL_DIRS=$(find /backup/mongodb/incremental -type d -name "$FULL_BACKUP_DATE*" -o -name "$TARGET_DATE*" | sort)

# Step 4: Apply oplog entries up to the target timestamp
for DIR in $INCREMENTAL_DIRS; do
  if [ -d "$DIR/local" ]; then
    echo "Applying oplog entries from $DIR..."

    # Extract and filter oplog entries
    mongorestore \
      --host mongodb-restore.example.com \
      --port 27017 \
      --username restore_user \
      --password "$RESTORE_PASSWORD" \
      --authenticationDatabase admin \
      --db $TEMP_DB \
      --oplogReplay \
      --oplogLimit $TARGET_TIMESTAMP \
      --gzip \
      $DIR/local
  fi
done

# Step 5: Verify the restored data
mongo \
  --host mongodb-restore.example.com \
  --port 27017 \
  --username restore_user \
  --password "$RESTORE_PASSWORD" \
  --authenticationDatabase admin \
  --eval "db.getSiblingDB('$TEMP_DB').stats()"

# Step 6: Rename the temporary database to the target database
mongo \
  --host mongodb-restore.example.com \
  --port 27017 \
  --username restore_user \
  --password "$RESTORE_PASSWORD" \
  --authenticationDatabase admin \
  --eval "db.adminCommand({renameCollection: '$TEMP_DB.pigs', to: '$RESTORE_DB.pigs'})"
```

#### 2. Single Collection Recovery

Restore a specific collection without affecting others:

```bash
#!/bin/bash
# Single Collection Recovery Script

# Parameters
COLLECTION="pigs"
BACKUP_DATE="20230615"
RESTORE_DB="paal"

# Step 1: Restore only the specified collection
mongorestore \
  --host mongodb-restore.example.com \
  --port 27017 \
  --username restore_user \
  --password "$RESTORE_PASSWORD" \
  --authenticationDatabase admin \
  --db $RESTORE_DB \
  --collection $COLLECTION \
  --gzip \
  /backup/mongodb/full/$BACKUP_DATE/$RESTORE_DB/$COLLECTION.bson.gz
```

#### 3. Document-Level Recovery

Restore specific documents based on query criteria:

```javascript
// Document-Level Recovery Process

// Step 1: Restore the collection to a temporary collection
// (Using mongorestore command from previous example, but with a different target collection)

// Step 2: Identify and copy the documents to recover
db.getSiblingDB('paal_restore').pigs.find({
  pigId: { $in: [1001, 1002, 1003] }
}).forEach(function(doc) {
  // Check if document exists in the target collection
  const existingDoc = db.getSiblingDB('paal').pigs.findOne({ _id: doc._id });

  if (existingDoc) {
    // Document exists, update it
    db.getSiblingDB('paal').pigs.updateOne(
      { _id: doc._id },
      { $set: doc }
    );
  } else {
    // Document doesn't exist, insert it
    db.getSiblingDB('paal').pigs.insertOne(doc);
  }
});

// Step 3: Clean up the temporary collection
db.getSiblingDB('paal_restore').pigs.drop();
```

### Backup Verification

All backups are verified to ensure they can be successfully restored:

#### 1. Automated Verification

```bash
#!/bin/bash
# Backup Verification Script

# Parameters
BACKUP_DATE="20230615"
VERIFY_DB="paal_verify"

# Step 1: Restore the backup to a verification database
mongorestore \
  --host mongodb-verify.example.com \
  --port 27017 \
  --username verify_user \
  --password "$VERIFY_PASSWORD" \
  --authenticationDatabase admin \
  --db $VERIFY_DB \
  --drop \
  --gzip \
  /backup/mongodb/full/$BACKUP_DATE/paal

# Step 2: Run verification queries
mongo \
  --host mongodb-verify.example.com \
  --port 27017 \
  --username verify_user \
  --password "$VERIFY_PASSWORD" \
  --authenticationDatabase admin \
  --eval "
    // Check document counts
    const pigCount = db.getSiblingDB('$VERIFY_DB').pigs.countDocuments();
    const farmCount = db.getSiblingDB('$VERIFY_DB').farms.countDocuments();
    const userCount = db.getSiblingDB('$VERIFY_DB').users.countDocuments();

    // Check specific important documents
    const adminUser = db.getSiblingDB('$VERIFY_DB').users.findOne({role: 'admin'});
    const mainFarm = db.getSiblingDB('$VERIFY_DB').farms.findOne({name: 'Main Farm'});

    // Print verification results
    print('Verification Results:');
    print('Pig Count: ' + pigCount);
    print('Farm Count: ' + farmCount);
    print('User Count: ' + userCount);
    print('Admin User Found: ' + (adminUser !== null));
    print('Main Farm Found: ' + (mainFarm !== null));

    // Overall verification status
    const success = pigCount > 0 && farmCount > 0 && userCount > 0 &&
                   adminUser !== null && mainFarm !== null;
    print('Verification ' + (success ? 'PASSED' : 'FAILED'));

    // Exit with appropriate code
    quit(success ? 0 : 1);
  "

# Step 3: Check the verification result
if [ $? -eq 0 ]; then
  echo "Backup verification successful"
  # Send success notification
  curl -X POST -H "Content-Type: application/json" \
    -d '{"message":"Backup verification successful for '$BACKUP_DATE'"}' \
    https://alerts.example.com/api/notify
else
  echo "Backup verification failed"
  # Send failure alert
  curl -X POST -H "Content-Type: application/json" \
    -d '{"message":"ALERT: Backup verification failed for '$BACKUP_DATE'"}' \
    https://alerts.example.com/api/alert
fi

# Step 4: Clean up verification database
mongo \
  --host mongodb-verify.example.com \
  --port 27017 \
  --username verify_user \
  --password "$VERIFY_PASSWORD" \
  --authenticationDatabase admin \
  --eval "db.getSiblingDB('$VERIFY_DB').dropDatabase()"
```

#### 2. Quarterly Recovery Drills

The team performs quarterly recovery drills to ensure the recovery procedures work as expected:

1. **Full Recovery Drill**: Complete restoration of the database to a test environment
2. **Point-in-Time Recovery Drill**: Restoration to a specific point in time
3. **Disaster Recovery Drill**: Simulation of a complete data center failure

### Disaster Recovery Plan

The disaster recovery plan outlines the procedures for recovering from catastrophic failures:

#### 1. Recovery Time Objectives (RTO)

- **Tier 1 (Critical)**: < 1 hour
- **Tier 2 (Important)**: < 4 hours
- **Tier 3 (Normal)**: < 24 hours

#### 2. Recovery Point Objectives (RPO)

- **Tier 1 (Critical)**: < 5 minutes
- **Tier 2 (Important)**: < 1 hour
- **Tier 3 (Normal)**: < 24 hours

#### 3. Disaster Recovery Procedure

```
# Disaster Recovery Procedure

## Phase 1: Assessment and Declaration
1. Assess the extent of the disaster
2. Declare disaster recovery if primary data center is unavailable
3. Notify all stakeholders

## Phase 2: Infrastructure Provisioning
1. Activate standby infrastructure in secondary region
2. Verify network connectivity
3. Configure MongoDB servers

## Phase 3: Data Recovery
1. Restore the most recent full backup from cloud storage
2. Apply incremental backups to reach the latest possible state
3. Verify data integrity

## Phase 4: Application Recovery
1. Update application configuration to point to the recovered database
2. Restart application services
3. Verify application functionality

## Phase 5: Validation and Monitoring
1. Run validation tests to ensure system integrity
2. Monitor system performance
3. Verify all critical business functions

## Phase 6: Communication and Reporting
1. Communicate recovery status to stakeholders
2. Document the incident and recovery process
3. Conduct post-incident review
```

### Backup and Recovery Monitoring

The backup and recovery processes are continuously monitored:

#### 1. Monitoring Metrics

- **Backup Success Rate**: Percentage of successful backups
- **Backup Duration**: Time taken to complete backups
- **Backup Size**: Size of backup files
- **Verification Success Rate**: Percentage of successful verifications
- **Recovery Time**: Time taken to recover in drills

#### 2. Alerting

Alerts are configured for backup and recovery issues:

- **Failed Backups**: Immediate alert if a backup fails
- **Backup Size Anomalies**: Alert if backup size changes significantly
- **Verification Failures**: Alert if backup verification fails
- **Missed Backups**: Alert if scheduled backups are missed

#### 3. Reporting

Regular reports are generated to track backup and recovery health:

- **Daily Backup Report**: Summary of all backups in the last 24 hours
- **Weekly Backup Analysis**: Trends and anomalies in backup metrics
- **Quarterly Recovery Drill Report**: Results of recovery drills
- **Annual Disaster Recovery Test Report**: Comprehensive assessment of DR capabilities

## Conclusion

The PAAL system's database schema is designed to efficiently store and retrieve data related to pig monitoring and farm management. The schema uses MongoDB's document-oriented approach to provide flexibility while maintaining data integrity through validation rules. Relationships between collections are implemented through reference fields, and indexes are strategically placed to optimize query performance.
